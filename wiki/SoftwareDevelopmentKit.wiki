#summary The SDK design.
#labels Phase-Design,SDK

= Introduction =

The SDK provides containers and algorithms as a framework for the purpose of creating synth engines. It doesn't make any sound on it's own but take care of all the mind numbing details of memory allocation and signal routing. 

As long as we get the interface for it right the implementation can be improved and optimized later without breaking anything. A first iteration goal is to design a set of stable and working interfaces, later iterations will deal with improving the actual implementation.

The SDK has five major parts:

 * _Wrapper_. A container for an engine. The SDK will provide a number of common wrappers (JACK application, DSSI, LV2, VSTi, Audio Unit, RTAS, Python module, etc.). The host is responsible for interfacing with the outside world on behalf of the engine: input/output audio, setting parameters and translating MIDI into OSC messages the engine understand.

 * _Engine_. Has signal input/outputs and can send/receive messages. Container for voices, manage voices and mix down all voices for final output.

 * _Voice_. A single instance of the processor graph, the signal path for a voice. Has signal input/outputs and can send/receive messages. Container for one or more nodes.

 * _Node_. Processor nodes in the graph that can be connected to each other. Has signal input/outputs and can receive messages. Act as an adapter for blocks.

 * _Block_. Implements the generation or modification of samples.

There are two types of communications:

 * _Signal_. Sample based data continuously flowing through the processing graph. Normally audio data but can also be sample based control signals (so called "CV" data).

 * _Message_. Sparse. Generated by various events and handled by [Controller controllers]. Used for setting parameters, receive musical data and communication with the GUI.