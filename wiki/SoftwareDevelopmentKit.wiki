#summary The SDK design.
#labels Phase-Design

= Introduction =

The SDK provides containers and algorithms as a framework for the purpose of creating synth engines. It doesn't make any sound on it's own but take care of all the mind numbing details of dynamic memory allocation and signal routing. 

As long as we get the interface for it right the implementation can be improved and optimized later without breaking anything. A first iteration goal is to design a set of stable and working interfaces, later iterations will deal with improving the actual implementation.

The SDK has four major parts:

 * _Host_. A container for an engine. The SDK will provide a number of common hosts (JACK application, DSSI, LV2, VSTi, Audio Unit, RTAS, Python module, etc.). The host is responsible for interfacing with the outside world on behalf of the engine: input/output audio, setting parameters and translating MIDI into messages the engine understand.

 * _Engine_. Has signal input/outputs and can receive/send messages. Container for voices, manage voices and mix down all voices for final output.

 * _Voice_. A single instance of the processor graph, the signal path for a voice. Has signal input/outputs and can receive/send messages. Container for one or more nodes.

 * _Node_. Processor nodes in the graph that can be connected to each other. Has signal input/outputs and can receive/send messages. A node either directly implement sample generation and modification or act as an adapter for such objects.

There are two types of communications:

 * _Signal_. Sample based data continously flowing through the processing graph. Normally audio data but can also be sample based control signals (so called "CV" data).

 * _Message_. Sparse. Generated by various events and handled by [Controller controllers]. Used for setting parameters, recieve musical data and communication with the GUI.
